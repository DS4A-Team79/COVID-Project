{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9c0bec",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (3.3.4)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.11.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.20.1)\n",
      "Requirement already satisfied: us in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/mourtallah/Library/Python/3.9/lib/python/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (8.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.9/site-packages (from seaborn->-r requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: jellyfish==0.6.1 in /usr/local/lib/python3.9/site-packages (from us->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from sklearn->-r requirements.txt (line 6)) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19921f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import base64\n",
    "import us as us\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "353ac1f2",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/state_funding.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f002ed3cda24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# borough_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/state_funding.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mfunds_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/state_funding.csv'"
     ]
    }
   ],
   "source": [
    "# for json formatted info\n",
    "\n",
    "# with open('data/borough_data.json') as f:\n",
    "#     borough_data=json.load(f)\n",
    "# borough_data\n",
    "\n",
    "with open('data/state_funding.csv') as f:\n",
    "    funds_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03878ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b0f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the state and the total funds allocated to each state, for 2021\n",
    "funds_df = funds_df.drop(labels=['Funding Based on Average Number of Unemployed', 'Funding from Even Distribution', 'CRF Top-Up'], axis=1) #only interested in the total funding\n",
    "funds_df.loc[:, \"Total Funding\"] = funds_df.loc[:, \"Total Funding\"].str.replace(r\"$\", \"\", regex=True)\n",
    "funds_df.loc[:, \"Total Funding\"] = funds_df.loc[:, \"Total Funding\"].str.replace(r\".\", \"\", regex=True)\n",
    "funds_df.loc[:, \"Total Funding\"] = funds_df.loc[:, \"Total Funding\"].str.replace(r\",\", \"\", regex=True) #remove irrelevant characters from numerics\n",
    "funds_df = pd.melt(funds_df, id_vars=['State'], value_vars=['Total Funding'], ignore_index=True) #reorganizing the dataframe with the states as index values\n",
    "funds_df = funds_df.drop(labels=\"variable\", axis=1)\n",
    "funds_df = funds_df.dropna()\n",
    "funds_df = funds_df.rename({\"value\":\"Total Funds\"}, axis=1)\n",
    "funds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#responsible for converting the monetary values to billions\n",
    "def convert_to_billions(vals):\n",
    "    new_vals = []\n",
    "    for val in vals:\n",
    "        val = val.replace(val[-8:], \"\")\n",
    "        val = val[0:len(val) - 3] + '.' + val[-3:]\n",
    "        new_vals.append(val)\n",
    "    return new_vals\n",
    "\n",
    "vals = funds_df[\"Total Funds\"].values\n",
    "funds_df[\"Total Funds\"] = pd.Series(convert_to_billions(vals))\n",
    "funds_df = pd.DataFrame(data=funds_df[\"Total Funds\"].values, index=funds_df[\"State\"], columns=[\"Total Funds (in billions)\"] )\n",
    "funds_df = funds_df.copy().drop(index=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved the df as csv\n",
    "# funds_df.to_csv('data/cleaned_state_funds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cleaned_state_funds.csv') as f:\n",
    "    clean_funds_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eb6db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,16))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "ax = sns.barplot(data=clean_funds_df, x=clean_funds_df.State, y=clean_funds_df['Total Funds (in billions)']).set_xticklabels(labels=clean_funds_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ae181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_funds_df = clean_funds_df.drop(columns=\"Unnamed: 0\")\n",
    "# clean_funds_df.to_csv('data/cleaned_state_funds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b5804",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/CARES_state_funds_2020.csv') as f:\n",
    "    cares_funds_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cac8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,16))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "ax = sns.barplot(data=cares_funds_df, x=cares_funds_df.State, y=cares_funds_df['Total Funds (in billions)']).set_xticklabels(labels=cares_funds_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cares_funds_df = cares_funds_df.drop(columns=\"Unnamed: 0\")\n",
    "# cares_funds_df.to_csv('data/CARES_state_funds_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a000ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged 2 datasets into one final funds per state dataset\n",
    "\n",
    "clean_funds_df.columns = ['State', 'Total Funds for 2021 (in billions)']\n",
    "cares_funds_df.columns = ['State', 'Total Funds for 2020 (in billions)']\n",
    "clean_funds_df = clean_funds_df.merge(cares_funds_df, how=\"inner\", on=\"State\")\n",
    "# clean_funds_df = clean_funds_df.set_index('State')\n",
    "clean_funds_df.to_csv('data/final_state_funds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f903e5d",
   "metadata": {},
   "source": [
    "### Run the cell below to get the new state funds results per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411631a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/final_state_funds.csv') as f:\n",
    "    final_state_funds=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60155dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state_funds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b805499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_state_funds = final_state_funds.set_index('State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state_funds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79768e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/2019_Census_US_Population_Data_By_State_Lat_Long.csv') as f:\n",
    "#     population_df=pd.read_csv(f, delimiter=',')\n",
    "    \n",
    "with open('data/final_state_funds_with_pop.csv') as f:\n",
    "    population_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d244c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funds per person\n",
    "# population_df = population_df.rename(columns={'STATE':'State', 'POPESTIMATE2019':'Estimated Population (2019)', 'lat':'Latitude (of Capital)', 'long':'Longitude (of Capital)'})\n",
    "# population_df = final_state_funds.merge(population_df, on=\"State\")\n",
    "\n",
    "# population_df[\"Funds Per Person (2021)\"] = (population_df[\"Total Funds for 2021 (in billions)\"] * (10**9))/population_df[\"Estimated Population (2019)\"]\n",
    "# population_df[\"Funds Per Person (2020)\"] = (population_df[\"Total Funds for 2020 (in billions)\"] * (10**9))/population_df[\"Estimated Population (2019)\"]\n",
    "population_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24680b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_df.to_csv('data/final_state_funds_with_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for population, failed\n",
    "\n",
    "# pop_cols = ['NAME', 'POPESTIMATE2019']\n",
    "# population_df = population_df[pop_cols]\n",
    "# population_df = population_df.groupby(['NAME'], as_index=False).sum()\n",
    "# population_df = population_df.rename(columns={'NAME':'State'})\n",
    "# state_pop_funds = final_state_funds.merge(population_df, on=\"State\")\n",
    "\n",
    "population_df.to_csv('data/final_state_funds_with_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172c7ec",
   "metadata": {},
   "source": [
    "### Normalizing the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adce875",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/final_state_funds_with_pop.csv') as f:\n",
    "    population_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ea9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_df=population_df.loc[population_df['State'] != \"District of Columbia\"].reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79a2eb",
   "metadata": {},
   "source": [
    "#### Normalized the total funds cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_2021_arr = np.array(population_df['Total Funds for 2021 (in billions)'])\n",
    "funds_2020_arr = np.array(population_df['Total Funds for 2020 (in billions)'])\n",
    "normalized_2021 = preprocessing.normalize([funds_2021_arr])\n",
    "normalized_2020 = preprocessing.normalize([funds_2020_arr])\n",
    "normal_list = []\n",
    "normal_list2 = []\n",
    "for element in normalized_2021[0]:\n",
    "    normal_list.append(element)\n",
    "for element in normalized_2020[0]:\n",
    "    normal_list2.append(element)\n",
    "\n",
    "normal_series = pd.Series(normal_list)\n",
    "normal_series2 = pd.Series(normal_list2)\n",
    "\n",
    "population_df['Normalized Funds 2021'] = normal_series\n",
    "population_df['Normalized Funds 2020'] = normal_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "ax=sns.barplot(data=population_df, x='State', y='Normalized Funds 2020').set_xticklabels(labels=population_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1eb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "ax=sns.barplot(data=population_df, x='State', y='Normalized Funds 2021').set_xticklabels(labels=population_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437cc8a",
   "metadata": {},
   "source": [
    "#### Normalized the per person cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbda46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_per_person_2021_arr = np.array(population_df['Funds Per Person (2021)'])\n",
    "funds_per_person_2020_arr = np.array(population_df['Funds Per Person (2020)'])\n",
    "normalized_2021 = preprocessing.normalize([funds_per_person_2021_arr])\n",
    "normalized_2020 = preprocessing.normalize([funds_per_person_2020_arr])\n",
    "normalized_list = []\n",
    "normalized_list2 = []\n",
    "for element in normalized_2021[0]:\n",
    "    normalized_list.append(element)\n",
    "for element in normalized_2020[0]:\n",
    "    normalized_list2.append(element)\n",
    "\n",
    "normal_series = pd.Series(normalized_list)\n",
    "normal_series2 = pd.Series(normalized_list2)\n",
    "\n",
    "population_df['Normalized Per Person Funds 2021'] = normal_series\n",
    "population_df['Normalized Per Person Funds 2020'] = normal_series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_per_person_2021_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5265d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "ax=sns.barplot(data=population_df, x='State', y='Normalized Per Person Funds 2020').set_xticklabels(labels=population_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e57bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "ax=sns.barplot(data=population_df, x='State', y='Normalized Per Person Funds 2021').set_xticklabels(labels=population_df.State, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_df.to_csv('data/final_state_funds_with_pop.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a330c1f",
   "metadata": {},
   "source": [
    "## Processing HRR datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f7956",
   "metadata": {},
   "source": [
    "# Don't focus on the HRR datasets, as they are estimates, not official numbers!\n",
    "- wasted time unfortunately :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/HRR_perc_20.csv') as f:\n",
    "    HRR_20_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert location of hospitals from cities to states\n",
    "\n",
    "HRR_20_df = HRR_20_df.dropna()\n",
    "def city_to_state(vals):\n",
    "    new_vals = []\n",
    "    for val in vals:\n",
    "        val = str(us.states.lookup(val[-2:]))\n",
    "        new_vals.append(val)\n",
    "    return new_vals\n",
    "\n",
    "HRR_20_df['HRR'] = city_to_state(HRR_20_df.HRR.values)\n",
    "HRR_20_df = HRR_20_df.drop(columns=['Adult Population', 'Population 65+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1acabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns containing predicted values of the dataset as we are not trying to predict anything on the hospitals,\n",
    "# if they were official values from the hospitals, they could be useful.\n",
    "\n",
    "# HRR_20_df = HRR_20_df.drop(columns=HRR_20_df.columns[7:])\n",
    "# HRR_20_df.to_csv('data/HRR_info.csv', index=False)\n",
    "\n",
    "\n",
    "# HRR_info_df.head()\n",
    "# HRR_20_df.groupby(['HRR']).sum()\n",
    "# HRR_20_df.dtypes \n",
    "# need to replace special characters (% , .) and convert objects to numerics\n",
    "# for percentage columns, left shift twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a92b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/HRR_info.csv') as f:\n",
    "#     HRR_info_df=pd.read_csv(f, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67f241",
   "metadata": {},
   "source": [
    "## New Hospital Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e02e6",
   "metadata": {},
   "source": [
    "### Some Things to Keep mind\n",
    "- Some columns are unnecessary. Share with others what could possibly be used/what should be kept\n",
    "- I don't want to drop rows with nulls, NaN errors, because unless duplicated, each row should contain useful info\n",
    "- Convert the values to int/floats (numerics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8123690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/Patient_Impact_Hospital_Capacity.csv') as f:\n",
    "    pihc_df=pd.read_csv(f, delimiter=',')\n",
    "    \n",
    "pihc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67a284",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pihc_df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pihc_df.iloc[:,11:].dtypes == \"object\"\n",
    "\n",
    "pihc_df.astype({'previous_week_personnel_covid_vaccinated_doses_administered_7_day_max':'int64'})\n",
    "\n",
    "# temp_cols = pihc_df.iloc[:,11:].select_dtypes(\"object\").columns\n",
    "# for row in temp_cols:\n",
    "#     try:\n",
    "#         pihc_df.astype({'{row}':'int64'})\n",
    "#     except:\n",
    "#         pihc_df.astype({'{row}':'float'})\n",
    "            \n",
    "#     pihc_df.iloc[:,11:].select_dtypes(\"object\")\n",
    "    \n",
    "# temp_df = pihc_df.iloc[:,11:].select_dtypes(\"object\").astype('int64', errors='ignore')\n",
    "# temp_df = temp_df.select_dtypes(\"object\").astype('float', errors='ignore')\n",
    "# temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b84b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa29804",
   "metadata": {},
   "outputs": [],
   "source": [
    "pihc_df.loc[pihc_df[11:].dtypes == \"object\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pihc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422f44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pihc_df.dtypes.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}