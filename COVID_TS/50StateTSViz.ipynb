{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd ## for linear algebra\n",
    "import numpy as np ## for computation, and arrays.\n",
    "from scipy.signal import argrelextrema, find_peaks_cwt ## for finding extrema\n",
    "import matplotlib.pyplot as plt ## for plotting\n",
    "import seaborn; seaborn.set() ## for custom plotting\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytics surrounding the pandemic, namely time series, were the most  ubiqutious form of data news that Americans had access to: state governing bodies often appearing on regular policy breifings with line graphs of new case or moving averages of new cases. We assume that that similar means were used to make and assess the effectiveness of state policy decisions such as stay at home orders and mask ordinances. \n",
    "\n",
    "This notebook details the derivation of scalar score by which each state's time series can be arranged ordinally and thus compared directly. Local regression?\n",
    "\n",
    "Consider the time series, $T$, of new daily cases for some state over some finite date-range. Having mapped the time series $T$ to a smooth function $T'$ using  series to a smooth function using local polynomial regression, there exists some sets of local minima and local maxima, $V$ and $P$ respectively, collectively defined as $E$, on $T$.\n",
    "\n",
    "$$ Z = \\lambda(V,P,\\Delta{t},\\Delta{y})) = \\sum_{p \\in P} \\#p (\\Delta{t})^{\\tan(\\frac{\\Delta{y}}{\\Delta{t}})} + \\sum_{v \\in V} (\\Delta{t})^{\\tan(\\frac{\\Delta{y}}{\\Delta{t}})} $$\n",
    "\n",
    "Thus, $ Z = \\lambda(V,P,\\Delta{t},\\Delta{y})$ is defined below where $\\Delta{y}$ is the inter-extrema change in cases and $\\Delta{t}$ is the inter-extrema change in time (number of days), and $\\#p$ is the cardinality of the maxima. \n",
    "\n",
    "This function is useful as undesirable qualities of a state's time series of new cases are penalized with higher scores, as the inclusion of $\\#p$ ensures that state's whose time series has several peaks are found as less performant than those with fewer, more decisive relationship with the virus. \n",
    "\n",
    "$\\Delta{t}$ captures the duration of the inter-extrema times, i.e. how long was the uninterrupted rise in cases leading up to a peak of trough. \n",
    "\n",
    "The inclusion of the tangent function serves two purposes is appropriate because the the tangent of the inter-extrema angle is the ratio of the inter-extrema cases and number of days. This is the angle of increase of decrease between points and serves as a notion of the intensity of the rise or fall of cases between peaks that is independent of the population of the state, allow us to forgoe normalizing, or otherwise transforming the data. This also ensures that the influence of an inter-extrema intervals is relative to the ratio of $\\Delta{y}$ and $\\Delta{t}$ such that a flat interval will have a minor effect on the total score, even if it is, say, the fourth or fifth peak in the time series. Such intervals are not common, but they do occur as part of the local regression polynomial regression.\n",
    "\n",
    "We postulate that this function $\\lambda$ of each time series will yield a unique score $Z \\in R$ that will be high for states that had poor performance in containing the virus, and low for states the performed better.\n",
    "\n",
    "What follows is a class object StateTS, which can load the time serieses for particular state and plot them along with thier extrema. calculate display statistics on the time serie and calculate Z for a given state. The last code block plots this information for all 50 states for easy comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = ! ls States #saves US states in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTS:    \n",
    "    \"\"\"Instantiates Time Series Analysis object and charts for State\n",
    "\n",
    "    Args: \n",
    "        state (str): The full name of the state (e.g. \"New Jersey\" but not \"NJ\")\n",
    "        [min_date] (str): first day of analysis window in YYYY-MM-DD format. Jan 22, 2020 by default.\n",
    "        [max_date] (str): last day of analysis window in YYYY-MM-DD format May 2, 2021 by default.\n",
    "    \n",
    "    Attributes:\n",
    "        attr1 (str): Description of `attr1`.\n",
    "        attr2 (:obj:`int`, optional): Description of `attr2`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, state, min_date=\"2020-01-22\", max_date=\"2021-05-02\"):\n",
    "        \n",
    "        # Load State data\n",
    "        self.state_name = state # collects the name of the state\n",
    "        self.ts=pd.read_csv(f'./States/{state}/{state}_smooth.csv').transpose() # loads data and takes its transpose\n",
    "        self.date_range=pd.date_range(start=min_date, end=max_date) # sets date range\n",
    "        \n",
    "        # Engineering State data Series\n",
    "        self.ts.index=self.date_range # assigns date range to index\n",
    "        self.ts.index.name=\"Date\" # Renames index to \"Date\"\n",
    "        self.ts=self.ts.rename(columns={0:\"new_cases\"}) # Renames Series column to \"new_cases\"\n",
    "        \n",
    "        # Collecting peaks and troughs\n",
    "        self.minima=list(argrelextrema(self.ts.values, np.less_equal, order=1)[0]) # collects minima from time series.\n",
    "        self.maxima=list(argrelextrema(self.ts.values, np.greater_equal, order=1)[0]) # collects maxima from time series.\n",
    "        self.points=np.sort(self.minima+self.maxima) # combines minima and maxima into one list of points of interest.\n",
    "        self.peak_frame=self.ts.iloc[self.points] # subsets points of interest against main ts.\n",
    "        #self.peak_frame=self.peak_frame.rename(columns={0:\"number_of_new_cases\"}) \n",
    "        \n",
    "        # DELTAS\n",
    "        self.time_delta=[] # list for interpeak times. \n",
    "        self.case_delta=[] # list for interpeak volume of new cases.\n",
    "        self.slopes=[] #  ratio's of interpeak volumes and times.\n",
    "        \n",
    "        for i in range(len(self.peak_frame)-1): ## collects lists of interpeak times and new case volumes\n",
    "            self.time_delta.append(-1*(self.peak_frame.index[i]-self.peak_frame.index[i+1]).days)\n",
    "            self.case_delta.append(-1*int((self.peak_frame.values[i]-self.peak_frame.values[i+1])))\n",
    "    \n",
    "            \n",
    "        self.df=pd.DataFrame(self.time_delta, self.case_delta)\n",
    "        self.df=self.df[self.df.iloc[:,[0]]>1]\n",
    "        self.df.dropna(axis=0, inplace=True)\n",
    "        self.df=self.df.reset_index()\n",
    "        self.df=self.df.rename(columns={0:\"test\",1:\"test1\"}) # why doesn't this work?\n",
    "        print(self.df)\n",
    "\n",
    "        \n",
    "        self.case_delta=self.df.iloc[:,0]\n",
    "        self.time_delta=self.df.iloc[:,1]\n",
    "        \n",
    "        #for i in range(len(self.time_delta)-1): ## collects list of interpeak volume/time ratio's (slopes)\n",
    "        #    print(self.time_delta[i])\n",
    "        #    self.slopes.append((self.case_delta[i])/self.time_delta[i]+1)\n",
    "        \n",
    "        self.up_slopes=[]\n",
    "        \n",
    "\n",
    "        for slope in self.slopes:\n",
    "            if slope > 0:\n",
    "                self.up_slopes.append(slope) \n",
    "        \n",
    "        self.down_slopes=[]\n",
    "\n",
    "        for slope in self.slopes:\n",
    "            if slope < 0:\n",
    "                self.down_slopes.append(slope) \n",
    "        \n",
    "        #np.array(self.slopes).sum()\n",
    "        #np.array(self.slopes).max()\n",
    "        #np.array(self.slopes).min()\n",
    "\n",
    "#    def chart_ts(self):\n",
    "#        print(self.ts.new_cases)\n",
    "#        self.ts.new_cases.plot(figsize=(20,8), alpha=.3)\n",
    "#        plt.show()\n",
    "        \n",
    "    def chart_peaks(self):\n",
    "        self.ts.new_cases.plot(figsize=(30,12), alpha=.3)\n",
    "        ilocs_max_raw=argrelextrema(self.ts.values, np.greater_equal, order=1)[0]\n",
    "        ilocs_min_raw=argrelextrema(self.ts.values, np.less_equal, order=1)[0]            \n",
    "        ilocs_min=np.setdiff1d(ilocs_min_raw, ilocs_max_raw)\n",
    "        ilocs_max=np.setdiff1d(ilocs_max_raw, ilocs_min_raw)\n",
    "        print(self.ts.iloc[ilocs_min])\n",
    "        print(ilocs_min)\n",
    "        print(self.ts.iloc[ilocs_max])\n",
    "        print(ilocs_max)\n",
    "        \n",
    "\n",
    "        self.ts.iloc[ilocs_max].new_cases.plot(style='.', lw=10, color='red', marker=\"v\")\n",
    "        self.ts.iloc[ilocs_min].new_cases.plot(style='.', lw=10, color='blue', marker=\"^\")\n",
    "        plt.title(f\"{self.state_name}\")\n",
    "        plt.show()\n",
    "\n",
    "    def get_extrema(self):\n",
    "        pass\n",
    "    \n",
    "    def get_points(self):\n",
    "        return(self.points)\n",
    "        \n",
    "    def get_sorted_points(self):\n",
    "        self.points.npsort()\n",
    "        \n",
    "    def get_inc_seq(self):\n",
    "        points=minima+maxima\n",
    "        points.sort()\n",
    "    \n",
    "    def get_decr_seq(self):\n",
    "        points=minima+maxima\n",
    "        points.sort()\n",
    "        \n",
    "    def get_all_slopes(self):\n",
    "        return(self.slopes)\n",
    "        \n",
    "    def get_up_slopes(self):\n",
    "        up_slopes=[]\n",
    "        for slope in self.slopes:\n",
    "            if slope>0:\n",
    "                up_slopes.append(slope) \n",
    "        return(up_slopes)\n",
    "    \n",
    "    def get_down_slopes(self):\n",
    "        up_slopes=[]\n",
    "        for slope in self.slopes:\n",
    "            if slope>0:\n",
    "                up_slopes.append(slope) \n",
    "        return(up_slopes)\n",
    "    \n",
    "    def report(self):\n",
    "        \n",
    "        print(f\"Time Series Report for {self.state_name}\")\n",
    "        print(f\"{self.peak_frame}\")\n",
    "        print(\"Minima\")\n",
    "        print(self.minima)\n",
    "        print(\"Maxima\")\n",
    "        print(self.maxima)\n",
    "        print(\"*******ANALYSIS OF DELTAS**********\")\n",
    "        print(\"Time Deltas\")\n",
    "        print(self.time_delta)\n",
    "        print(\"Case Deltas\")\n",
    "        print(self.case_delta)\n",
    "        print(\"*******ANALYSIS OF SLOPES**********\")\n",
    "        print(f\"Slopes for {self.state_name}\")\n",
    "        print(self.slopes) \n",
    "        print(f\"Sum of Slopes: {np.array(self.slopes).sum()}\")\n",
    "        #print(f\"Maximum of Slopes: {np.array(self.slopes).max()}\")\n",
    "        #print(f\"Minimum of Slopes: {np.array(self.slopes).min()}\")\n",
    "        self.chart_peaks()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f9f82ebe9170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mus_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mStateTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStateTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5589b97fb65a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state, min_date, max_date)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Load State data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;31m# collects the name of the state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./States/{state}/{state}_smooth.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loads data and takes its transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sets date range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "states=[]\n",
    "for state in us_states:\n",
    "    StateTS(state).chart_peaks()\n",
    "    states.append(StateTS(state).state_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
